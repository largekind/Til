---
title: "DeepLearning Introduction"
date: 2023-07-31T22:43:40+09:00
categories: ["DXQuest"]
tags: ["DXQuest", "AI_Beginner"]
---
# DeepLearning Introduction

## 概要

DeepLearningの入門を復習もかねて簡潔にまとめていく

## 人工知能

- 学んだこと
  - 弱い人工知能/強い人工知能
    - AGIなど呼ばれている。説明は割愛
  - 第一次人工知能ブーム
    - 1950 - 1960年のブーム。将棋や囲碁などが出てきた時代
  - 第二次人工知能ブーム
    - 1980 - 1990年のブーム。エキスパートシステムが出てきた時代
  - 第三次人工知能ブーム
    - 2014年くらいにAlexNetが出てきて、その後爆発的に研究が行われてきた時代
    - ビックデータなどを活用した研究などが増えた

## 機械学習

- 学んだこと
  - 機械学習
    - 人工知能の分類の1つ
    - 特定のパラメータをもとにデータを最適化していく
  - 特徴量
    - 対象を判別するための数値情報
    - 特徴量を設計し、選択させることで学習可能にする
  - 教師あり学習
    - 正解(ラベル)が存在しているデータに対して行う学習方法
    - 大抵は分類と回帰問題に対して行う学習となる
  - 教師なし学習
    - 正解なしのデータに対しての学習
    - クラスタリングや次元削減の処理が該当する
  - 強化学習
    - 行動に対して報酬を支払うことで、学習を進めていく手法
    - 正解がなく、囲碁や将棋といった組合せ爆発があるゲームで使われているような印象
  - 機械学習の注意
    - 過去データがないと学習できない
    - データと質と量は担保しておくこと
      - 無駄なノイズなどが大量にあると学習できない
      
## 深層学習

- 学んだこと
  - 深層学習
    - Neural Networkをモデルとした機械学習
    - ブームは言わずもがなAlexNet(2012)
  - Neural Network
    - ノードとエッジで構成される構成
    - 入力層 - 隠れ層 - 出力層という形になっている
    - 純伝播では重み付き和と活性化関数で次のノードに情報を伝搬させていく
    - 逆伝播では逆に得られた出力と正解の差から最適化アルゴリズムを用いて情報を伝搬させる
  - 活性化関数
    - ReluとかSigmoidとか。出力層に用いられる関数。
    - これがないと非線形性が取れず、表現が線形のものにしかならなくなる
  - 勾配降下法(SGD)
    - 最適化法で真っ先にでるもの。勾配から最適解を求めようとするアプローチ
  - Auto Encoder(AE)
    - 代表的な教師なし学習に使われるモデル。次元圧縮などで使われる
    - DAE(Denoising Auto Encoder)といった、次元圧縮することでノイズ除去を行うようなパターンで使われる
      - 例 : 欠陥検出など
  - Variational AutoEncoder(VAE)
    - こちらもよく使われるAEの一種。
    - 分散と計算を隠れ層の途中に入力として入れることで、結果を変更できるようになったAE
  - 敵対的生成ネットワーク(GAN : Generative Adversarial Network)
    - 生成機と識別機で交互に競い合わせることでより良いデータを作ろうとするモデル。
      - よく警察と泥棒の関係に例えられる印象
  - Q学習
    - 状態を入力とし、行動の価値(Q値)を学習・出力させて行われるDNNを用いた強化学習の手法
  - 方策勾配法
    - Q学習が行動の価値そのものを学習したのに対し、こちらはどの行動をするかの確率を報酬が高くなるように学習する
    - AlphaGoに使われた手法として有名