---
title: "画像認識"
date: 2023-04-05T00:00:00+09:00
---
# 画像認識

## 画像分類

いつもの。画像からクラス分類するだけ

## 物体検出

YOLOとかのやつ。画像から物体が「どこに」、「それが何か」を示すやつ

### IoU(Intersection over Union)

Intersection : 共通部分  
over Union : 和集合  
物体検出に使われている評価指標。「どこに」を示す評価指標。  
予測した領域と正解領域の共通部分が一致している度合いをパーセンテージで表す。

## セグメンテーション

ピクセル単位の物体検出(クラス分類)を行うタスク。
画像分類がただのクラス似合ったのに対し、こちらはクラスを割り当てた画像を出力する

自動運転など、細かい検出が必要な分野で応用される

## 画像分類用データセット

### MINST

数字0-9のデータ

### CIFER-10/CIFER-100

乗り物や動物のデータセット。後ろの10/100はクラス数  
ピクセルが32*32と少し小さめ

### Fashon-MINST

服とかの画像

### Food101

食べ物101個

### Image-Net

ジャンル問わないバカみたいに大きい画像データセット  
2万クラスあるので、事前学習させたモデル使ったりとか

## 物体検出/セグメンテーション用データセット

### Pascal VOC dataset

基本的なデータセット。カテゴリ20で1万程度ある

### COCO-Common Objenct in Context

セグメンテーション用データセット  
YOLOで使ってたような気がする

## ILSVRC

Imagenetを用いた画像分類コンペティション  
2010年スタートで色々やってて、2012年にAlexNetでCNNが入って来て色々とやってきている  
現在は終わって別の大会に引き継がれてる

## アーキテクチャとモデル

- アーキテクチャ : 学習前の構造だけのニューラルネットワーク  
- モデル : 上記に学習が入ったもの。学習後のネットワーク  

モデルという言い方は既に学習済みのNNを指すので注意

## 画像分類モデル

### AlexNet (2012)

ディープラーニング火付け役。スタンダートな構造だが、活性化関数にRelu関数が入ったもの。  
**初めてRelu関数やドロップアウトの技術が入ってきた、CNNのベースとなったネットワーク**

### VGG(2014)

よく使うやつ。
**max poolingで大域的な情報を圧縮するという考えが入ったモデル**  
また、フィルタサイズを減らし、ネットワーク層を増やすことで**受容野はそのまま、パラメータを減らして効率化が出来た**

### GoogleNet(2014)

**多層化のための工夫を織り込んだアーキテクチャ**  
Inception Moduleとか色々工夫が入ってる

#### Inception Module

大きなフィルタを小さいフィルタで分割計算することで、パラメータを減らした手法

フィルタサイズの異なる畳み込み層を並列に配置し、それぞれの結果をチャネル方向に結合して出力するモジュール

#### Auxilirary Loss

勾配消失の問題を防ぐため、途中の中間層でもLoss計算、逆伝搬を行う手法  
これにより、疑似的なアンサンブル学習(疑似的な複数ネットワークでの学習)ができ精度向上となっている

#### GAP (Global Average Pooling)

各チャネルごとで平均を取る手法  
CAMでも出てきたやつ。これにより、最後のクラスへの出力部分で全結合層が無くせるのでパラメータ削減 + 過学習の防止になる

#### Pointwise Convolution

チャネル方向での畳み込み  
パラメータ数が$1/f^2$となるため、次元削減とかに使えたりする。MobileNetでも使用されている。

### Resnet (2015)

Skip Conectionなどが入ったResidual Blockを導入、残差を学習することで超多層化が出来るようになったネットワーク  
過去、自分が自論文で使ってたネットワーク

#### Residual Block

層を跨ぐ結合 Skip Connection(identity mapping)を用いて残差を学習するブロック  
入力がそのまま出力に入りこむため、層が深くなることに勾配計算 -> 微分により値が小さくなっていた問題が解決された  
**単純にskip入れるだけで勾配消失が改善するので、これ以降のモデルにもこの考えが入るようになった**

### Wide Resnet (2016)

Resnetのチャネル数を増やして計算量と層を減らして精度をupさせたResnet

オリジナルのResnetと比較して、以下の利点を持つ
- オリジナルのResnetより学習が高速
- オリジナルのResnetより層数が少ない
- オリジナルのResnetより各Residual Blockのフィルタ数が多い

その分、**オリジナルのResnetよりモデルパラメータが多い**(メモリを多く消費する)

### Dense Net (2016)

Skip Connectionを別レイヤー（後ろの層全て）に繋げられるようにし、
残差をさらに計算可能にしたモデル
Pooling的な処理はTransition Layerとして別枠に追加して対応している

### Mobile Net (2017)

計算量削減を実現したアーキテクチャ  
Depthwise Separable Convolutionと呼ばれる、畳み込み計算を更に分けた計算によって計算を削減

#### Depthwise Separable Convolution

平面方向の畳み込みとチャネル方向の畳み込みを分割して行うことで計算量削減を実現したConv計算

### Efficient Net (2019)

モデルの深さ/広さ/解像度を同時に調整するアーキテクチャ
MobileNetでハイパーパラメータとなっていた部分を自動的に探索、調整する形式になっている
#### MBConv

チャネルごとに重みづけを行い、MobileNetと同じConv計算を行う畳み込み計算

#### Compound Scaling Methods

深さ、広さ、解像度を定式化して、１つのハイパーパラメータとまとめて、
そのパラメータをグリッドサーチすることで、自動的に必要なパラメータを探索可能にする方式

## 物体検出モデル

### Selective Serch + SVN

**Deep Learning関係ないモデル**

何かがありそうな領域を大域的な範囲から局所的な範囲まで適当に取ってきてSVMに渡し、
SVN側で何かあるかどうか and それが何かを識別させていたモデル

#### ROIs(関心領域)

この辺に何かありそうだなを切り出した画像。  
方法としてSelective searchが用いられたりする
### R-CNN (2013)

Selective Searchで候補領域を探索したもの(ROIs)を入力とし、そのデータをCNNで解析して特徴量を出し、
さらに別のネットワークやSVNに入れ込むことで、分類/回帰結果を出力するモデル。
最後の出力にSVMを使っていたりなどする部分もあるので、学習・認識速度が遅いデメリットがある。
### Fast R-CNN (2015)

ROIsではなく通常の画像を入力とし、そこから出た特徴マップに対してSelective Searchを用いてROIsを作成するモデル。
作成した後はSVMなり全結合層レイヤーなりで解析して分析を行う。

特徴マップの対応部分を固定サイズで切り分けてプーリングを行うROI Poolingが存在する。

#### ROI Pooling

出力した特徴マップのROIsはそのままだと画像サイズ不一致で入力できないため、
それっぽい領域に4分割して、その平均値を用いて元の画像にする手法
### Faster R-CNN (2015)

Selective Searchを使ってROIsを使っていた部分もCNNを用いて抽出する形式にしたもの。
これにより、End to Endでの学習が可能となった

R-CNN系列は一環としてクソ重いという問題がある(1秒に5枚くらいしか画像分析できない)

### YOLO (2016)

You Only Look Once

過去、他の先輩が使っていたモデル。

「You Only Look Once(人生は一度きり)」というだけあって、
一度画像見ただけで画像の検出と識別を1回で行うようにしたモデル。

#### YOLOの解析方法

1. 7*7のバウンティボックスを画像全体に設定（豆腐みたいに画像全体をさいの目切りするようなイメージ）
2. バウンティボックス内にある物体を検出、ROIsをいくつか作成（さいの目ごとに検出処理）
3. 最後にバウンティボックスごとに重なったクラスを１つに絞らせる（重複した検出を消す）

さいの目切りを最初にする関係で、バウンティボックスの「位置」や「範囲」が制限される問題がある。
（密集した画像や様々な物体が重なった場合、とたんに弱くなる）

### SSD (2016)

Single Shot MultiBox Detectorの略

さいの目切りをいくつかのサイズで用意して切ることで、様々な候補領域を表現できるようにしたYOLOの改良版

#### Hard Negative Mining

画像中の「拝啓」と「物体」の不均衡度を調整する処理

### Mask R-CNN

Faster R-CNN改良版。

層を追加することで「物体検出」「インスタンスセグメンテーション」「姿勢推定」全てが同一のCNNで可能になったモデル

#### ROI Align

ROI Poolingで取れなかった部分を取れるように切り出し可能にしたやつ

#### Instance Segmantation

ただのマルチタスク学習に近い気がする。

物体検出にインスタンスセグメンテーション(個体ごとでの領域分割が入ったセグメンテーション)も入れ込んで精度向上させている

### FCOS

YOLO/SSD改良版

バウンティングボックスの設定を自動的にする（アンカーフリー）ことで、全体的な制度向上したモデル。

#### FPN (Featutre Pyramid Networks)

昔自作モデルで流用したモデル。

次元圧縮の後に特徴を増やすような層を追加、ボトムアップ的な情報も抽出しようとしたやつ

#### Focal Loss

数が少ないクラスに対しては重みをつけてLossを計算する手法

#### Center-ness

バウンティングボックスの中心に着目して、そこの値を予測+損失関数の重みにした手法

## セグメンテーションのモデル

### FCN

自分が一番使用したモデル。DeConv層が入っている

一般的な畳み込みのネットワークの最後FCNを「畳み込み層」にする。

また、大きさの違う複数の特徴マップをDeConv層で拡大し、
大きさを揃えたうえで**各画素同士で足し合わせることで**物体の詳細な情報を捉える。

**FCNが無いので入力画像サイズが可変**

*※U-Netと違い、特徴マップの合わせるのにチャネル結合はしないので要注意*
#### DeConvolution(Transepose Convolution)

逆畳み込みやtranspose Convlutionとも記載される畳み込み計算の１つ。1つ隙間を開けてパディングされた画像を作成、
Convolutionを行うことで特徴マップ自体の画像サイズを大きくする畳み込み計算を行う。

実質的に画像サイズを広くさせるような畳み込み処理
### U-Net

Encoderの各層の情報を対応するDecoderの情報にshortcut Connectionすることで、
元の空間情報を維持したまま画像を出力させるモデル。

アーキテクチャがU字っぽいのでU-Net

### SegNet

FCN/U-Netが中間層を保存する関係でメモリ効率が悪い問題があるのを解決したモデル

**Max-Pooling index**と呼ばれるMaxpooling層で抽出したpixelのインデックスのみ保存する手法により特徴マップをアップサンプリングすることで、メモリ効率が悪い問題を解決した

#### up-pooling

中間層の保存部分での工夫。

**プーリング層で選んだ座標の情報だけ保存して渡すことで、Skip Connection時にメモリ効率を大幅に削減する**

