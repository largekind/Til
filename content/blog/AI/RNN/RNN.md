---
title: "RNN"
date: 2023-04-05T00:00:00+09:00
tags: ["Python", "AI", "RNN"]
categories: ["AI"]
---
# RNN

時系列データを取り扱うDL系列。RNNとかLSTMとかGRUとか

## Recurrent Neaural Network (RNN)

Reccurent : 回帰  
回帰的に前の入力情報を次のネットワークに伝搬させることで、時系列データの学習を可能にしたDNN

## BPTT (Backpropagation Through Time)

時間方向の逆伝搬を行う処理  
前時間の入力を別の追加したネットワークに入れこむ形にし、伝搬可能にすることで実現している

## RNNの逆伝搬

連鎖律を用いて計算していく形式でしていく。計算が難しいので検索して理解しておく

## 勾配消失

よくある層が深くなると学習ができなくなってしまうやつ。  
原因は「活性化関数」を通ることで出力されるデータが段々少なくなるため
RNNでも最後の出力で活性化関数を通る関係で勾配消失が発生する

## 勾配爆発

前の情報が強すぎて逆に勾配が爆発してしまう現象  
原因対策として、一定以上の勾配は閾値を取って頭打ちにする**勾配クリッピング**を用いる

## 勾配クリッピング

L2ノルムを用いて、勾配が一定以上にならないように頭打ちを行う処理

## RNNの伝搬

### 順伝搬

普通に計算。ただの計算グラフなのでそこまで考えない  
**入力する地点で重みとバイアスが入り込むことを忘れないようにする**

### 逆伝搬

**登場するパラメータと出力値で連鎖律を行う**  
順伝搬で使っていた+/*の計算やtanhといった活性化関数に惑わされないようにする


## 派生モデル

### エコーステートネットワーク

RNNにある重みの中で入力の重みと隠れ層の重みはランダムに固定、
**出力の重みのみを学習**することで勾配消失や勾配爆発を抑制する手法

### スキップ接続

隠れ層を1時刻以上スキップさせて接続、長期依存性の課題を対策したもの

### Leaky Unit

隠れ層に線形結合を導入、移動平均の効果を得る手法

### 双方向RNN (Bi-directional RNN)

[link](bi-RNN.md)