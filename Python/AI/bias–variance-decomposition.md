# バイアス・バリアンス分解

損失関数の期待値を最小化するにあたり、各々を最小化するために項で分解すること。

期待値を分解すると「バリアンス項」「バイアス項」「ノイズ項」に分解できる。
$$
E[L(y(X),t)] =
\underset{バリアンス項}
{\underline{E[\{y(x) - E[y(x)]\}^2]}}+ 
\underset{バイアス項}
{\underline{E[\{y(x) - E[t(x)]\}^2]}}+
\underset{ノイズ項}
{\underline{E[\{E[t(x)] - t\}^2]}}
$$

$$
\begin{align}
y(x) : 予測モデル \\
E[y(x)] : 予測の期待値 \\
E[t(x)] : 理想的な予測の期待値 \\
t : 目的変数の真値
\end{align}
$$

**バイアスとバリアンスはトレードオフの関係を持つ**

## バリアンス項

予測値の分散。
予測された値が予測の期待値からどれだけ離れているかで決決される

これが大きいとモデルは過学習する

## バイアス項

予測と目的変数(理想的な予測モデル)の期待値の差。

これが大きいとモデルは未学習となる。

## ノイズ項

データのノイズ。機械学習で小さくできない部分


