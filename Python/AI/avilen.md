
# CNN

自研究で使用していたやつ。Convolution Neural Network  
下記の流れで特徴マップを学習していく手法  

> 入力 -> 畳み込み演算 -> プーリング -> 畳み込み演算 -> ... -> 最終的な出力

## 畳み込み演算

フィルタで行列計算をするアレ 詳細はGoogle  
主に情報の抽出に使用

### プーリング

データの圧縮で使用するもの  
情報の統合により、大域的な情報を抽出する

- 最大値プーリング(max pooling) : フィルタでのmax値を出す  
- 平均値プーリング(average pooling) :フィルタでのmean値を出す

### im2col

画像を行列計算するために列に分割する処理。  
行列の内積を算出して一気に畳み込み演算を行う  
フィルタを適用する画像領域を一行化する処理することで、  
１行化した画像領域と１列化したフィルタで行列積算が可能となり、計算が高速化する

## 正規化（画像）

ネットワークが深くなると、非線形変換の繰り返しによりデータ分布が変わることがある（**内部の共変量シフト**）
### Batch Normalization

全てのバッチごとに正規化(平均0、分散1化)する処理  
各ノードの値をミニバッチ単位で正規化して、スケールをそろえる（バッチ正規化）  
**正則化としても機能する** (L2正則化やDrropoutの必要性が小さくなる)

### Layer Normalization

レイヤーごとに正規化を行う処理  
オンライン学習やRNNで使用する

### Instance Normalization

各チャネルで独立で画像の縦横方向のみで平均・分散をとる  
画像分野ではバッチ正規化の代わりで注目されている

### Group Normalization

チャネルをG個でグルーピングしてLayer Normalizatoin/Instance Normalizationの中間的な正規化を行う  
セグメンテーションなどで利用

# RNN

時系列データを取り扱うDL系列。RNNとかLSTMとかGRUとか

## Recurrent Neaural Network (RNN)

Reccurent : 回帰  
回帰的に前の入力情報を次のネットワークに伝搬させることで、時系列データの学習を可能にしたDNN

## BPTT (Backpropagation Through Time)

時間方向の逆伝搬を行う処理  
前時間の入力を別の追加したネットワークに入れこむ形にし、伝搬可能にすることで実現している

## RNNの逆伝搬

連鎖律を用いて計算していく形式でしていく。計算が難しいので検索して理解しておく

## 勾配消失

よくある層が深くなると学習ができなくなってしまうやつ。  
原因は「活性化関数」を通ることで出力されるデータが段々少なくなるため
RNNでも最後の出力で活性化関数を通る関係で勾配消失が発生する

## 勾配爆発

前の情報が強すぎて逆に勾配が爆発してしまう現象  
原因対策として、一定以上の勾配は閾値を取って頭打ちにする**勾配クリッピング**を用いる

## 勾配クリッピング

L2ノルムを用いて、勾配が一定以上にならないように頭打ちを行う処理

## RNNの伝搬

### 順伝搬

普通に計算。ただの計算グラフなのでそこまで考えない  
**入力する地点で重みとバイアスが入り込むことを忘れないようにする**

### 逆伝搬

**登場するパラメータと出力値で連鎖律を行う**  
順伝搬で使っていた+/*の計算やtanhといった活性化関数に惑わされないようにする

# AE

## Auto Encoder

生成モデルの一種。EncoderとDeconderに分かれ、適当な入力に応じて何かしらを出力するモデル  
Encoder -> 潜在変数z -> Decoderの形でzに次元圧縮して何かしらの特徴に圧縮して、Decoderでその圧縮された特徴を用いてデータを出力する  

入ったものを圧縮してそのまま出すしかしてないので、**中間的な画像が出せないデメリットがある**

## Variational Autoencoder

通称VAE  
EncoderとDecoderの間にあるzを確率分布として平均、分散を求め、そこからサンプリングでzを取る形式になったもの  

確率変数をいじれば中間的な画像を連続的に出せる

### Reparametrization Trick

VAEの学習で逆伝搬をするために、**ガウシアンノイズを用いてサンプリングを近似的に行うことで、逆伝搬可能にした方法**  
直訳すると「再パラメータ化トリック」というだけあって、サンプリングの処理をガウシアンノイズのパラメータで行うトリックを用いている

### posterior collpage

**VAEの問題** 表現力が高いDecoder(例:PixelCNN)などを用いると潜在変数が無視された生成が出てしまう  
対策として潜在変数zを離散的なベクトルに変えたVQ-VAEなどがある

## VQ-VAE

潜在変数に離散ベクトルを用いて学習させることで、上記の問題を解決させたVAE

## GAN

いつもの。Generative Adversal Network(敵生成ネットワーク)  
GeneratorとDiscriminatorを戦闘させて学習していくニセ札と警察の関係的な発想で生まれたネットワーク

# 強化学習

## 教師あり学習

正解がわかっているデータをもとに、入力データと対応する正解の出力の関係を学習する  
画像分類などが該当

## 教師なし学習

与えられたデータが持つ構造そのものを学習。正解そのものが無い  
SVMやクラスタリングが該当
## 強化学習

**報酬**をもとに、最適な意思決定を作成するための学習方法  
五目並べとか遺伝子的アルゴリズムとかが該当

## マルコフ決定過程

「状態」 + 「行動」+ 「報酬」で最適化を行う処理  
確率的に変化させる決定に報酬や行動によるウェイトを追加したもの

### マルコフ過程

「状態」で一意に決まる確率過程のこと  
数学者であるアンドレイ・マルコフにちなんで命名された  
これに「行動」と「報酬」が入るとマルコフ決定過程になる
### マルコフ性

今の状態に応じて次の状態が決定するという性質。  
*今*が次を決めるやつ。過去の自分に影響されたり、未来からドラ〇もんが来て状態が勝手に変化するとかは無いよっていうやつ

## 方策

どう行動を決定するかを考えるための決まりや戦略の基準となる部分。

### 割引率

**未来に対する報酬に対する影響に対して重みづけを行うための報酬のウェイト値**  
直近だけでなく、未来の報酬もある程度考慮して考えるための影響度の度合い

### 累積報酬和

価値を表す総和の式。  
R = 直近の報酬 + 次の報酬 * 割引率 + さらに次の報酬 * 割引率^2 + ... = 報酬*時間分の割引率の総和

上を価値関数として見て、最大化するのが目的となる


### 価値関数

強化学習における目的関数のこと  
実質的に累積報酬和をmaxへ持っていくための行動と状態を表す式が価値関数になる

### 最適ベルマン方程式

*「今の価値」* + **今後の価値の期待値**で決まる価値関数  
「価値を最大化する行動」 = 「価値を最大かする最適な方策」を結びつけることが出来る

## 強化学習におけるアプローチ

### 価値関数ベース

価値を最大化するような行動をする（最適な行動をする）のを軸に評価するアプローチ  
**価値そのものをモデル化**して、行動自体は別のアルゴリズムに代用させる形式

### 方策ベース

価値を最大するような行動ルール(方策)を見つけようとするのを軸に評価するアプローチ  
**方策（行動の選択方法）をモデル化**する方式

## 価値関数ベースのアプローチ

### 行動価値関数(Q)

一定の条件時での価値関数の値を求める関数。  
ある状態である状態を取ったときの価値に限定した方法

### 価値関数法

価値関数をもとに行動を選択、試行を繰り返して価値関数を更新する手法  
**環境に対する知識(環境ダイナミクス)が完璧にある時に使用できる**

#### 環境ダイナミクス

状態転移確率と報酬が既知である状態  
迷路とか完璧に設計されているような、既に分かっている問題などが該当

### 環境のサンプリング

**実際に行動してみて、その得た情報で価値関数を更新する方式**  
とりあえずやってみよう理論

#### モンテカルテ法

最後までプレイして、その報酬から価値を推定する方式  

#### TD法(Temporal Difference Learning)

その時までに得た報酬で価値関数を更新する手法  
(即時報酬で更新していく)

具体的には「１つ先の報酬とその行動価値」と「現在の行動価値」との差を用いて、最適な行動価値関数へ更新していく手法。
このアイデアをアルゴリズム化したのがQ学習になる。

### 局所解への対策

強化学習は初期の方策（行動）に依存しやすい傾向があるため、  
たまには今までの学習を無視して行動させようという対策がある

#### ε-greedy方策

確率εでランダム行動させる方策

#### ソフトマックス方策

ある程度の今までの学習を用いて、ボルツマン分布に従い行動を設定させる  
（完全ランダムではなく、ある程度今までの学習も信用してランダムな行動をする）

## TD法の分類
### Q学習

**方策OFF型**  
次の状態がどれくらいの価値を持つかを*現在推定されている値のMax*を用いてQ値を更新する手法  
「明日は自分はベストな行動取るだろう」と信じて学習していく手法  
最適なベスト値(Max値)を取っているので学習が安定する。

### SARASA

**方策OFF型**  
今の方策に従って値を更新していく手法  
「未来より、今の自分を信じる」として学習していく手法  
現在の方策で得た値を取る(ランダム性がある)ため学習が若干不安定だが、局所解に陥る危険が少ない


## 方策勾配法(方策ベース)

土の手をどれくらいの確率で選択すべきかの**方策**自体を直接予測  
**未来の盤面を列挙しない** + 相性の良い手法と組み合わせて、性能が良い方策を実現可能！

### 方策勾配定理

方策パラメータΘに対する偏微分で得られる方策勾配が満たす性質のこと  
**行動価値関数のQ値が分かればベストな方策がわかるよ定理**  

価値関数をΘで偏微分するメチャクチャ面倒な式なので覚えたほうが早い  
*デメリットとしてQ値を求めるのが難しいので、Q値の平均値などを工夫して必要がある*

#### ベースライン関数

現在の報酬からベース分引いて、分散を抑えるための関数

#### アドバンテージ関数

行動価値関数から推定される価値関数を引くことで、ある程度の分散を抑える関数


## 方策ベースのアプローチ

### REINFORCEアルゴリズム

REINFORCE : 強化  
実際に得られた報酬の平均を使って近似したものをQ値とする方法  
「死ぬたびに学習→強くなる」方式

### Actor Critic

Actor Critic : 演者 - 評論家  
状態価値をNeaural Networkを用いて推測させ、方策を決定させる方式  
「演者が上手く演技しているか、評論家が評価して強くしていく」方式

### A3C

Asynchoronous advantage Actor Crinic の略  
Actor Crinicに加えて、パラメータの更新を非同期で行う*Asynchrouns*と推定にAdvantageを用いる形式  
(Asynchoorus + Advantage + Actor : A3)  
「演者がどれだけ有利に事を運んで演技しているかを、評論家が一度にいっぱい見ながら評価して強くしていく」方式

#### A2C

A3Cの同期分散処理版モデル  
Asynchorousが消えているのでA2C  
**同期するのでGPUで使いやすいメリットがある**


#### ACER

A3Cベースに勾配オフ型にし、Experience Replay(経験再生)を利用したモデル  
過去の履歴も学習できるようになり、更に収束しづらい問題は*Retrace*と呼ばれる手法で解決している

#### UNREAL

Unsupervied reinforcement and auxiliary learning : 教師なしでの補助学習  
A3Cベースに補助タスクも同時学習させたモデル  
「色んな学習を同時に強化学習させよう」モデル

# DL実用

## 事前学習(pre-training)

よくあるやつ。予め大量のデータセットでモデルを学習させておくこと

## 転移学習

学習済みのモデルに層を追加して、**追加した部分の箇所だけ学習させる**方式

## fine-tuning

よくあるやつその2。学習済みモデルの重みを初期値として**全体のモデルを再学習させる**方式  
転移学習が一部に対し、fine-tuningは全体を学習させる

## ワンショット学習

データに対し1ラベルを付与した画像などで学習させる方式  
例としては顔の学習など

## ゼロショット学習

ラベルを付与せず、特徴ベクトルなどに変換して学習を行わせる方式  
Decoderとかが近そう

## 半教師あり学習

一部データだけラベル付与して最初は学習、  
予測した結果を用いてラベルなしデータにラベル付けして更に学習を行う形式

## 自己教師あり学習

同じラベルの画像をデータ拡張してもラベルは同じなのを利用して、  
データ拡張後の画像の予測が元画像の答えと近づくように学習していくような形式  
ある意味Tripnet Networkに近い気がする（後述）

## マルチタスク学習

昔自研究で検討しようとしたやつ。複数のタスクに対しての予測を行い学習をする形式

## 距離学習

2つ以上のデータ間の類似性を用いて学習すること  
何を類似性にするかは色々種類があるので割愛。（例:ユーグリット距離とかハミング距離とか)

### Siamese Network

SIamese : シャムと読む シャム双生児が由来の模様（頭２つ、体１つの奇形児）  
同じペアのデータセットを作って、2つの入力を同じネットワークに入れ、  
出力が同じになるように学習させていくネットワーク

### Triplet Network

Triplet : 三つ子  
同じペア、違うペアで３人組を作って、  
同じペアに出力値を近づけ、違うペアには出力が遠さがるような学習をしていくネットワーク

#### Easy Negative

3つのペアのサンプリングを行うケースの1つ  
元画像に大して別ラベルの画像が元々遠い位置にサンプリングされてる場合、そもそも別カテゴリと見られて学習ができないもの

#### Semi-Hard Negative

3つのペアのサンプリングを行うケースの1つ  
元画像に対し、同じラベルの画像と別ラベルの画像がいい塩梅でサンプリングされており、学習がしやすい状況のもの

#### Hard Negative

3つのペアのサンプリングを行うケースの1つ  
元画像に対し、別ラベルの画像が元画像に近い場所にサンプリングされてしまい、  
別ラベル画像が元画像と同じラベルの画像と誤認されてしまう状況のもの

## メタ学習(Meta-Learning)

どのように学習すればよりよくNeural Networkを学習できるかを考えること  
メタ思考的な学習 モデルのハイパーパラメータどうするかetc...

### few-shot learning

少ない画像データで学習する手法のこと。  
その代表的な手法としてMAMLが存在している。
#### MAML(Model-Agnostic Meta-Learning)

何度か小さいデータセットで試しに学習を行い、  
その平均を初期値として取ることで学習の最適化を行わせる手法

## Explainable AI

説明可能なAIのこと  
例としてHeatmapなどを用いて何を着目して判断したかを見る

### CAM

Global Average pooling(GAP)で最後の出力を出している層に着目、  
そこの重みを各チャネルの画像として抽出して元画像と合成することでヒートマップを作る手法  
GAPが最終層となっているResNetなどでしか使えない欠点がある
#### Grad-CAM

畳み込みの最終層の特徴に着目してヒートマップを作る手法  
GAPがないネットワークでも使える利点があるため、現在の主流となっている

#### Guided-Grad CAM

GradCAMに加え絵、クラスに対しての勾配を求めて画像に入れこむ(Guided back propagation)することで、どこに着目しているのかを画像で見れる手法

### LIME

局所モデルを用意して、局所モデルを局所敵なデータで学習させ特徴量を見ることで、  
そのモデルが何を見ているかを間接的にわかるようにしようという手法

### SHAP

シャープレイ値（各特徴量を組み合わせた時にどれだけ貢献値があるか）を近似的に計算して、  
何が影響を与えているかを見れるようにした手法

## Graph Neaural Network

入力をグラフとして扱うNN。これにより構造そのものを表現し、学習可能となる。  
(例 : 化合物、文章、ソーシャルネットワーク)  
各グラフ間の関係をグラフ行列としてあらわして入力することで学習させている

### グラフ畳み込み

グラフに対する畳み込み計算を行うこと。
これにより、隣接するノードの関係など、様々な情報を抽出できる。
名前の通り、グラフ版Convolutionみたいなもの
### Relational Network

グラフ畳み込み計算を用いたニューラルネットワークのこと  
関係毎に畳み込みを行い特徴を抽出する。  
(活用例 : 企業ごとでの特徴や格付けの予測など)

# 画像認識

## 画像分類

いつもの。画像からクラス分類するだけ

## 物体検出

YOLOとかのやつ。画像から物体が「どこに」、「それが何か」を示すやつ

### IoU(Intersection over Union)

Intersection : 共通部分  
over Union : 和集合  
物体検出に使われている評価指標。「どこに」を示す評価指標。  
予測した領域と正解領域の共通部分が一致している度合いをパーセンテージで表す。

## セグメンテーション

ピクセル単位の物体検出(クラス分類)を行うタスク。
画像分類がただのクラス似合ったのに対し、こちらはクラスを割り当てた画像を出力する

自動運転など、細かい検出が必要な分野で応用される

## 画像分類用データセット

### MINST

数字0-9のデータ

### CIFER-10/CIFER-100

乗り物や動物のデータセット。後ろの10/100はクラス数  
ピクセルが32*32と少し小さめ

### Fashon-MINST

服とかの画像

### Food101

食べ物101個

### Image-Net

ジャンル問わないバカみたいに大きい画像データセット  
2万クラスあるので、事前学習させたモデル使ったりとか

## 物体検出/セグメンテーション用データセット

### Pascal VOC dataset

基本的なデータセット。カテゴリ20で1万程度ある

### COCO-Common Objenct in Context

セグメンテーション用データセット  
YOLOで使ってたような気がする

## ILSVRC

Imagenetを用いた画像分類コンペティション  
2010年スタートで色々やってて、2012年にAlexNetでCNNが入って来て色々とやってきている  
現在は終わって別の大会に引き継がれてる

## アーキテクチャとモデル

- アーキテクチャ : 学習前の構造だけのニューラルネットワーク  
- モデル : 上記に学習が入ったもの。学習後のネットワーク  

モデルという言い方は既に学習済みのNNを指すので注意

## 画像分類モデル

### AlexNet (2012)

ディープラーニング火付け役。スタンダートな構造だが、活性化関数にRelu関数が入ったもの。  
**初めてRelu関数やドロップアウトの技術が入ってきた、CNNのベースとなったネットワーク**

### VGG(2014)

よく使うやつ。
**max poolingで大域的な情報を圧縮するという考えが入ったモデル**  
また、フィルタサイズを減らし、ネットワーク層を増やすことで**受容野はそのまま、パラメータを減らして効率化が出来た**

### GoogleNet(2014)

**多層化のための工夫を織り込んだアーキテクチャ**  
Inception Moduleとか色々工夫が入ってる

#### Inception Module

大きなフィルタを小さいフィルタで分割計算することで、パラメータを減らした手法

#### Auxilirary Loss

勾配消失の問題を防ぐため、途中の中間層でもLoss計算、逆伝搬を行う手法  
これにより、疑似的なアンサンブル学習(疑似的な複数ネットワークでの学習)ができ精度向上となっている

#### GAP (Global Average Pooling)

各チャネルごとで平均を取る手法  
CAMでも出てきたやつ。これにより、最後のクラスへの出力部分で全結合層が無くせるのでパラメータ削減 + 過学習の防止になる

#### Pointwise Convolution

チャネル方向での畳み込み  
次元削減とかに使えたりする。確かMobileNetでも似たような物があったはず。

### Resnet (2015)

Skip Conectionなどが入ったResidual Blockを導入、残差を学習することで超多層化が出来るようになったネットワーク  
過去、自分が自論文で使ってたネットワーク

#### Residual Block

層を跨ぐ結合 Skip Connectionを用いて残差を学習するブロック  
入力がそのまま出力に入りこむため、層が深くなることに勾配計算 -> 微分により値が小さくなっていた問題が解決された  
**単純にskip入れるだけで勾配消失が改善するので、これ以降のモデルにもこの考えが入るようになった**

### Wide Resnet (2016)

Resnetのチャネル数を増やして計算量と層を減らして精度をupさせたResnet

### Dense Net (2016)

Skip Connectionを別レイヤー（後ろの層全て）に繋げられるようにし、
残差をさらに計算可能にしたモデル
Pooling的な処理はTransition Layerとして別枠に追加して対応している

### Mobile Net (2017)

計算量削減を実現したアーキテクチャ  
Depthwise Separable Convolutionと呼ばれる、畳み込み計算を更に分けた計算によって計算を削減

#### Depthwise Separable Convolution

平面方向の畳み込みとチャネル方向の畳み込みを分割して行うことで計算量削減を実現したConv計算

### Efficient Net (2019)

モデルの深さ/広さ/解像度を同時に調整するアーキテクチャ
MobileNetでハイパーパラメータとなっていた部分を自動的に探索、調整する形式になっている
#### MBConv

チャネルごとに重みづけを行い、MobileNetと同じConv計算を行う畳み込み計算

#### Compound Scaling Methods

深さ、広さ、解像度を定式化して、１つのハイパーパラメータとまとめて、
そのパラメータをグリッドサーチすることで、自動的に必要なパラメータを探索可能にする方式

## 物体検出モデル

### Selective Serch + SVN

**Deep Learning関係ないモデル**

何かがありそうな領域を大域的な範囲から局所的な範囲まで適当に取ってきてSVMに渡し、
SVN側で何かあるかどうか and それが何かを識別させていたモデル

#### ROIs(関心領域)

この辺に何かありそうだなを切り出した画像。  
方法としてSelective searchが用いられたりする
### R-CNN (2013)

Selective Searchで候補領域を探索したもの(ROIs)を入力とし、そのデータをCNNで解析して結果を出力するモデル。
ただし、最後の出力にSVMを使っていたりなどする部分もある。

### Fast R-CNN (2015)

ROIsではなく通常の画像を入力とし、そこから出た特徴マップに対してSelective Searchを用いてROIsを作成するモデル。
作成した後はSVMなり全結合層レイヤーなりで解析して分析を行う。

#### ROI Pooling

出力した特徴マップのROIsはそのままだと画像サイズ不一致で入力できないため、
それっぽい領域に4分割して、その平均値を用いて元の画像にする手法
### Faster R-CNN (2015)

Selective Searchを使ってROIsを使っていた部分もCNNを用いて抽出する形式にしたもの。
これにより、End to Endでの学習が可能となった

R-CNN系列は一環としてクソ重いという問題がある(1秒に5枚くらいしか画像分析できない)

### YOLO (2016)

You Only Look Once

過去、他の先輩が使っていたモデル。

「You Only Look Once(人生は一度きり)」というだけあって、
一度画像見ただけで画像の検出と識別を1回で行うようにしたモデル。

#### YOLOの解析方法

1. 7*7のバウンティボックスを画像全体に設定（豆腐みたいに画像全体をさいの目切りするようなイメージ）
2. バウンティボックス内にある物体を検出、ROIsをいくつか作成（さいの目ごとに検出処理）
3. 最後にバウンティボックスごとに重なったクラスを１つに絞らせる（重複した検出を消す）

さいの目切りを最初にする関係で、バウンティボックスの「位置」や「範囲」が制限される問題がある。
（密集した画像や様々な物体が重なった場合、とたんに弱くなる）

### SSD (2016)

Single Shot MultiBox Detectorの略

さいの目切りをいくつかのサイズで用意して切ることで、様々な候補領域を表現できるようにしたYOLOの改良版

### Mask R-CNN

Faster R-CNN改良版。

層を追加することで「物体検出」「インスタンスセグメンテーション」「姿勢推定」全てが同一のCNNで可能になったモデル

#### ROI Align

ROI Poolingで取れなかった部分を取れるように切り出し可能にしたやつ

#### Instance Segmantation

ただのマルチタスク学習に近い気がする。

物体検出にインスタンスセグメンテーション(個体ごとでの領域分割が入ったセグメンテーション)も入れ込んで精度向上させている

### FCOS

YOLO/SSD改良版

バウンティングボックスの設定を自動的にする（アンカーフリー）ことで、全体的な制度向上したモデル。

#### FPN (Featutre Pyramid Networks)

昔自作モデルで流用したモデル。

次元圧縮の後に特徴を増やすような層を追加、ボトムアップ的な情報も抽出しようとしたやつ

#### Focal Loss

数が少ないクラスに対しては重みをつけてLossを計算する手法

#### Center-ness

バウンティングボックスの中心に着目して、そこの値を予測+損失関数の重みにした手法

## セグメンテーションのモデル

### FCN

自分が一番使用したモデル。De Conv層が入っている

一般的な畳み込みのネットワークの最後FCNを「畳み込み層」にする。

**FCNが無いので入力画像サイズが可変**

#### deconvolution

逆畳み込みとも。1つ隙間を開けてパディングされた画像を作成、
Convolutionを行うことで特徴マップ自体の画像サイズを大きくする畳み込み計算を行う。

実質的に画像サイズを広くさせるような畳み込み処理
### U-Net

Encoderの各層の情報を対応するDecoderの情報にshortcut Connectionすることで、
元の空間情報を維持したまま画像を出力させるモデル。

アーキテクチャがU字っぽいのでU-Net

### SegNet

FCN/U-Netが中間層を保存する関係でメモリ効率が悪い問題があるのを解決したモデル

#### up-pooling

中間層の保存部分での工夫。

**プーリング層で選んだ座標の情報だけ保存して渡すことで、Skip Connection時にメモリ効率を大幅に削減する**

# 自然言語処理

人間がしゃべる言葉をコンピューターで処理させようというやつ

LSTMとかRNNとかSeq2Seqとか時系列的に処理していくアレ

## 単語埋め込み

単語をベクトル化すること。コンピュータに入力できるように数値化する

## Word2vec

単語をベクトル化するため、MLP(Multi Layer Perseptron : 全結合層)に入れて数値化する手法

実質的に単語 -> ベクトルにするためのAEに近いイメージ

### CBOW

単語をベクトル化するための学習方法の１つ。

単語を与えられた時、その空白を埋める形で単語の間の単語を予測をする学習法
(穴埋め問題形式で単語間の情報を学習)

例 : my _____ is  ->  間に来るのはnameなのかと予測・学習

### Skip-gram

単語をベクトル化するための学習方法の１つ。

単語を与えられたとき、その前後の単語を予測するような学習法
（マジカルバナナ形式で単語の前後を学習）

例 : ____ name ____ -> my name isとか？色々予測

## 機械翻訳

Google翻訳とかDeepLとか。

翻訳の手法に*ルールベース*と*統計ベース*の2種類がある

また、評価法としてPerplextiyとBLEUが使われる
### RBMT (Rule-Based Machine Translation)

ルールベースでの翻訳手法

予め登録済みのルールを適応して、訳文を出力する手法。

「文法ベースでの翻訳」に近い。論文とかへの解釈は精度高いが、口語とかスラングに弱い

### SMT (Statisitical Machine Translation)

統計ベースでの翻訳手法

文語・口語問わず訳せるかつ、データが充実しているのであれば人間を超える。
その代わり、当然データ依存かつデータが少ない場合は別の意味に問われてしまうなどがある。

**Deep Leaningを用いた翻訳はSMTとなる**

## 機械翻訳の評価指標

### Perplexity

「次の単語として絞り込めた候補単語数」を図る評価指標

つまり、「文法的にその文は変じゃないよね」を図る指標

### BLEU (bilingual evaluation understudy)

プロの翻訳者の役と近いかどうか、正解と生成した訳がどれだけ類似しているかを出す指標

類語などが考慮されずバリエーションも多い問題があるが、それでもこちらがスタンダードな指標となっている


### N-gram

ある文章を連続するn文字/n単語の塊に分割する手法。splitに近い

これとモデルを組み合わせて、「前何個までの情報をもとに文を予測するか」を推測する(**n-gramモデル**)

## Seq2Seq

文から他の分を生成するアーキテクチャ。

RNNをEncoder/Decoderに見かけて、データを入力、その情報をもとに系列データを出力する

### Reverse

エンコーダの入力分を反転させ、データを入力する

### Peeky(のぞき見)

エンコード結果を他の時系列の入力にも追加して渡す

実質的にskipConnectionのRNN版

## Attention

エンコーダの時系列的な隠れ層の出力を用いて、αで重みづけしてデコーダに渡すことで
どの時刻時の情報が主に文章に寄与しているかを渡せるようにした機構

ただエンコーダの隠れ層の出力を抽出して渡すだけでは逆伝搬できないため、
αで重みづけして渡す処理を加えることで逆伝搬できるように工夫されている。

αの取り方に*加法注意(Additive Attention)*と*内積注意(Dot-Production Attention)*がある

### Additive Attention

加法注意とも  

Attentionの重みaを求めるため、各エンコーダの隠れ状態全体と現在のエンコーダの隠れ状態をMLPに渡して、
重みを抽出するような計算を行う。

当然MLPがある都合上、パラメータは増えるし計算も複雑なので、余り使われない

### Dot-Product Attention

内積注意とも

Attentionの重みaを求めるため、各エンコーダの隠れ状態全体と現在のデコーダの隠れ状態にdotを使って内積を取る手法

### Self-Attention

1つの系列内(1文中)で各要素が他の要素にどのような関連があるかを見る

### Source Target Attention

Seq2Seqのように異なる系列間の各要素の類似度を算出する

### Attention付きbi-LSTM

そのままの意味。Attention機構を入れ込んだ双方向のLSTM

### Google Neural Machine Translation(GNMT)

Attention付きbi-LSTMにSkip-Connectionを入れて、更にGPUで並列処理可能にしたモデル

名前の通りGoogle開発

### Transformer

Attention機構のみをメインとして、単語の時系列的な情報は別の方法で学習させる形式にした新しい手法のモデル。
(LSTMが重すぎてGPUとかも有効活用できないので、変わりに時系列は別のベクトルとして扱い学習させる方式にした)

#### Positional Encoders

Transformerで時系列的な情報をLSTM経由せずに学習させるための工夫1

エンコーダに入れ込み学習する際、
単語の順序、位置関係をベクトル化して、元の埋め込みベクトルに付与する方法

#### Multi-Head Attention

並列的に複数のAttentionを計算、結合させる仕組みのこと

このままだと並列計算時に未来の情報もそのまま勝手に取ってAttentionを計算するので、
Transformerではそれを防ぐために「Masked Multi-Head Attention」と呼ばれる工夫を用いる
#### Masked Multi-Head Attention

Transformerで時系列的な情報をLSTM経由せずに学習させるための工夫2

デコーダにエンコーダの情報を入れ込む際、系列の後ろの要素（未来の情報）はマスクして隠すことで、
カンニング的に未来の情報を取ってくるような事をしないようにする工夫

### OpenAI GPT

一時期、「性能高すぎて悪用されそうだから公表できない」となった超精度の言語生成モデル

TransformerのEncorderを単語モデルに応用したアーキテクチャ。
GPT -> GPT-2 -> GPT-3と数字が増えるごとに大規模かつ膨大なパラメータでの学習が入っている。

### BERT

双方向にTransformerのEncoderを使ったモデル

GPTが単方向に対し、BERTは双方向となる
#### Maskerd Language Model(MLM)

文章の穴埋め問題を解くような形で学習を行う手法

#### Next Sentence Prediction(NSP)

2文から連続した文か不連続の文かを判定する手法。

これにより、会話がまだ続いているのか等を学習可能となる

### XLNet

MLMの工夫をし、実際のタスクを解くときにマスクによりノイズが出ていた部分を
予測単語の順序入れ替えなどで解決したモデル

### ALBERT

A Lite BERT

BERTを軽量化するためにWord Embedding(単語のベクトル化)にAuto Encoderの機構を入れたり、
各層のパラメータの重みを共有化させるなどをしてパラメータを削減、軽量化したモデル

### pronpt-based lerning

言語モデルを用いてプロンプト（適当な文）を生成することで
事前学習とFine-tuningのギャップを埋める学習法

# 音声処理

波形である音声データを何らかの周波数でデジタル化、
そのデータをもとに色々やろうねという処理

## デジタル化処理

### サンプリング

情報系なら知らないとバカなやつ。時間方向への離散化処理。
1秒間での切り分け数を「サンプリングレート」と呼ぶ（単位Hz)

当然、音声はアナログなので時間で離散化がいる

### 量子化

電圧方向（縦軸）での離散化。
音の大きさを電圧で示せるようにする。（※高さはHz)

*線形量子化*と*非線形量子化*がある。

#### 線形量子化

等間隔での量子化

#### 非線形量子化

等間隔ではない量子化。
0に近い部分は細かく切って、大きい音とかはおおざっぱに量子化するといった形にする。（人の耳の聞こえ方も非線形らしい）

### 符号化

量子化したデータを二進数にするだけ

## フーリエ変換

正弦波波形にいかなる波形も分解できるよというやつ。大学で習ったので詳細は略

### 窓関数

有限時間で波形を抽出するための関数。
矩形窓など色々種類がある。

窓関数を何度も適用して、離散的なフーリエ変換を計算するためのデータを作る

### 離散フーリエ変換 (DFT : Discrete Fourier Transform)

離散信号に対するフーリエ変換。

通常、無限時間+連続関数でしか適用できないフーリエ変換を有限時間かつ離散的な信号（デジタルなど）にも適用可能にした変換手法

代償として、計算量が$N^2$と死ぬほど遅い。そのため通常はFFTが使用される

### 高速フーリエ変換 (FFT : Fast Fourier Transform)

DFTのオーダーがN^2とめちゃくちゃ遅いので、複素数の対称性を用いて効率的に溶けるようにしたフーリエ変換

計算量が$N/2(Log_2(N) -1)$にまで削減されている

## 音声処理の手法

### Text To Speach (TTS)

テキストを音声にするやつ。ただの文字読み上げ

### 音声変換

ボイスチェンジャーのこと

## 音声合成の手法

自然言語と流れは似ている。元々ルールベースだったものが統計学的な出力にシフトしていったような形になる。

### 規則合成

ただのボイスチェンジャー的な合成法のこと

### 波形接続型音声合成

録音した音を組み合わせて文を読むこと。一昔前の機械音声とかが該当

### 統計的パラメトリック音声合成

統計的に学習した生成モデルから音声を出すこと

**Neural Networkでの音声モデルなどはこちらが該当**

## 音声処理のタスク

例としてスマートスピーカーを作る場合に必要な3つのタスクに着目する

### 多話者音声合成

色んな人の音声を学習、特定の人物の話者の話し方やイントネーションを学習
### TTS

入力テキストからどれだけ滑らかに文を発音できるようにするかを学習

### 音楽の合成

音楽データから、それっぽい音楽を生成できるようにしましたという話。余り情報がないため割愛

## Connectionist Temporal Classification (CTC)

音声認識において、発音とそれに合わせた時間+発音した内容を毎回用意していると当然死ぬ。
かつ、単語１つとっても伸ばし発音や短い発音などもあるので入力サイズも一定にならない

その対策として「無音」の情報を入れ込むことで入力サイズを一定化にする（パディング的なイメージ）

## WaveNet

音声を出力するための音声合成ニューラルネットワーク

中身的にはCNNとRNNを組み合わせて、時系列的に複数チャンネルであらわされた音声を出力するような形式となっている

構造的には3d Dilated Resnetに近い気がする
### Dilated Casual Conv

Dilated Conv + Causal Conv

Dilatedに加えて、「過去の情報のみを畳み込み演算する手法」であるCasual Convを組み合わせて使用する

Dilated Convが入るのは、Casual Convだけでは過去の直近情報しか取れないため、
受容野を広げるために使用されている

### Residual & Skip Connection

Resnetと同じ。入力を別レイヤの層につないで残差を学習させる

### Gated Activation Units

ただのLSTMのゲート。過去のデータをどこまで使用するかを持ち込む

## Conditional Wavenet

コナンのボイスチェンジャー的な奴。追加情報を加えることで、特定人物の声などを指定することができる

### Global COnditioning

全体的に条件を付ける。「～さん的な声」といった感じ

中身としてはLSTMのゲートと同じ式を加えるような形式

### Local COnditioning

一定的な時系列に条件付けを付与するような形式

# GAN

敵対的生成ネットワーク。まぁ詳しい情報はGoogle

2016年から一気にいろいろなGANが増えている

## noize to imgのGAN

ノイズから画像を生成する一般的なGANの紹介

### LAPGAN (2015)

Laplacian pyramid GAN

低解像度の画像をまず生成して、そこから少し高解像度の画像を生成、さらに...といった流れで繰り返して最終的に高い高解像度の画像を生成する手法

小さい解像度 -> 解像度+1 -> ... -> 解像度+高 といったピラミッド的な流れで進んでいく

### DCGAN (2015)

Deep Convolutional GAN

名前の通り、CNN版GAN。超有名なのであまり説明することがない...

Generatorは通常のConv、DiscriminatorにはdeConvを使ってる

#### Leakly Relu

DCGAN Discriminatorの学習で使われている活性化関数。
Reluの負値にもある程度傾斜をつけたRelu改良版。


通常のReluだとGeneratorまでに逆伝搬させる際、0以下の情報が伝搬せず学習が上手くできない問題があったためにLeakly Reluにした模様。

### PGGAN

Progressive Growing GAN

低解像度画像から徐々にレイヤーを追加、解像度を上げていくGAN

まさしく、レイヤーをピラミッド状に積み重ねていって学習するGAN

当然、レイヤー追加 = 高解像度化するたびにGANを変えていくので、アホみたいに計算量とメモリを食べる

### SinGAN

単一画像を高解像度化するように学習するやつ。

高解像度の入力画像に対して、ダウンスケール + ノイズを加えて訓練データとして学習、元画像と一致するように学習してくことで、
その後の超解像タスクや他アニメーションタスクなどの補完が可能なようにする。

#### reconstruction loss

SinGANに使われているLoss。

通常のGANの損失関数に加えて、「生成画像と入力した画像が離れないようにする」ためのLossを付与して損失とする

画像の離れ具合は**penalty coefficient**を指定して対応する。大きいほど多様性がある画像となる。

#### WGAN-gp

Wasserstein距離 + gradient penarityで作られたDiscriminator用損失関数。

「本物画像と入力画像のWasserstein距離」にgradient perarityと呼ばれるものを追加してある程度Discriminatorの学習を易化したもの


## クラス指定画像生成

通常のGANで使われている入力のノイズに加え、クラスも情報として入力することで、特定の画像を指定・出力可能になったGAN

### CGAN (Conditional GAN)

データセットのクラス情報も入力に与えることで、クラスの分類、精度upしたGAN

### InfoGAN (2016)

潜在変数を用いて、いろいろな変化をラベル付けなしで獲得できるようにしたGAN


### ACGAN (2016)

InfoGANに加えて、Discriminatorにクラス分類を追加、高精度な画像を出せるようにしたやつ

### SAGAN (2018)

Self-Attentionを入れることでConv層が局所的なものしか着目できない問題を解決、
大域的な関係性を見れるようにしたGAN

### BigGAN(2018)

でかいGAN。Truncated Trickと呼ばれる手法で出力画像の多様性と画質をトレードオフで調節できるようにしたGAN

Bigのため学習コストがやばい

### StyleGAN(2018)

Styleと呼ばれる情報を渡すことで、その特徴が入り込んだ画像を生成可能なGAN

スタイルを各層に取り込むためにAdaINと呼ばれる仕組みがある

#### AdaIN

Adaptive Instance Normalization

正規化したコンテンツ入力をスタイル入力にシフトさせる手法

## img -> imgのGAN(画像変換)

画像のスタイル変換や加工などを行うGAN

### pix2pix

画像間の関係性を考慮して学習することで、「画像 -> カラー」といった変換を可能にしたGAN

画像間の関係を出すため、きちんと対応付けされたペア画像を用意する必要がある難点がある

### Cycle GAN (2017)

馬 - シマウマみたいに画像のドメインを返還するGAN。

方法例として「馬-シマウマ」であれば、最初に「ウマ -> シマウマ」用Generatorで何かしらのウマ画像を渡し、
シマウマに生成された画像を「シマウマ -> ウマ」用のGeneratorに渡して、元のウマ画像に戻るように学習を行う

ペア画像を用意しなくても、対象の画像を大量にあつめることで包括的な特徴をとってきて変換可能になるGAN
### StarGAN (2017)

Cycle GANではA - Bと一対一でしか変換できないのを、複数の変換が可能な形にCycle GANを改良したもの

## その他 GAN

### Stack GAN

テキストから画像生成するGAN

CGANのクラス部分をテキストにし、GANを2段構造にしたアーキテクチャ。
(１段目でそれっぽい粗画像を作り、そこから高精度化するGANに渡す)

### Ano GAN

Anomary Detection with GAN

異常検知用のGAN。入力画像にできるだけ近い画像を生成するGAN

# 強化学習

細かい部分は前述。
基本的には行動毎の価値をもとに動作を決める「価値関数ベース」と
行動そのものを決定して学習する「方策ベース」がある。

QDNは「価値関数ベース」で価値そのものを産出する価値関数をNNで大体させる形でニューラルネットワークを導入していく

## DQN

ある状態における行動を入力、その行動価値の出力部分(Q関数)をディープラーニングで計算させる手法

おもにQ network + Target Q Networkの２つのNNを用いて、生徒と教師みたいな形で学習を進めていく

### Q Network

現状態から最適な行動を行うためのQ関数を産出、行動を決定させるためのネットワーク

### Target Q Network

次の状態を受け取り、その状態の価値を算出するネットワーク。

次の価値を予め求めて、その値を教師ラベルとすることで、Q Networkを更新していく形式になる。

ただし、毎ステップで価値が変わると教師があやふやになるので、何ステップかで一気に学習する形式となっている（fixed target q-network)

### Experience reply

ランダムにシャッフルしてミニバッチを作成する手法。
時系列的に相関したデータをうけとって学習すると新しい環境に対応しづらいので、その対策
### fixed target q-network

毎ステップで教師がぶれぶれな答えを出すのを抑制するため、特定ステップごとで学習をTarget Q-networkを行わせる手法

### reward clipping

与える報酬を±1にクリッピングする手法。タスク間での報酬の価値が分からなくなるが、学習がしやすくなるメリットがある。

## 強化学習モデル

### ApeX

ゲームじゃないぞ

Networkを複数の演者(actor)と、その演者から出てきた多様な経験・ノウハウを取得できるLearnerに分け、
Learnerから定期的に今までに学んできた情報をもらいながら複数のActorが行動をしていく形のモデル

監督(Learner)が得てきた経験などがまとまったマニュアルをもとに実際に労働者(Actor)が動き、
Actorの意見や経験を監督が受け取りマニュアルに反映、そのマニュアルをもとに...といった形式が近い気がする

#### 優先度付き経験再生

学習がより早く進む「経験」をサンプリングする。つまり、間違えた問題や知らない問題といった
TD誤差が大きくなりそうな物については優先的にサンプリングしていく

ただし、毎回同じ大きい誤差をサンプリングされたら困るので、ある程度重み付けはする（**重大度サンプリング**)

#### Dueling Network

状態価値関数とQ値を分けて出してからQを求める形式にすることで、
選択する行動によって「価値」が変わる状態と変わらない状態を分ける

どこで行動が別れるかをきちんと考えるためのネットワーク

#### Double Deep Q-Network

通常のQ Networkが出す「最大価値を出すはずの行動」をTarget Q-Networkに渡し、
その行動における次状態の価値を算出することで、Q NetworkとTarget Q-Networkの差異が広がりすぎるのを防ぐ手法

#### multi-step bootstrap target

nステップ先の報酬もあらかじめ推測、算出してLossにする手法。
ある程度先も考慮した誤差になる分、誤差が大きくなるデメリットがある

### R2D2/R2D3

ApexにLSTM導入することで、時系列的な情報も学習できるようにしたモデル。
R2D3はR2D2にさらに教師データに対して実際のプロ（人間）の経験を導入したもの

### AlphaGo Zero(2017)

AlphaGoの2017最新モデル。囲碁のモデル

DQNでQ関数を求めるのも限界だったため、予め有力候補をMCTS(モンテカルロ木探索)から使って求めておき、
そこからQ関数を求める形にしたモデル
