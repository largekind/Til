
# CNN

自研究で使用していたやつ。Convolution Neural Network
下記の流れで特徴マップを学習していく手法

> 入力 -> 畳み込み演算 -> プーリング -> 畳み込み演算 -> ... -> 最終的な出力

## 畳み込み演算

フィルタで行列計算をするアレ 詳細はGoogle
主に情報の抽出に使用

### プーリング

データの圧縮で使用するもの
情報の統合により、大域的な情報を抽出する

- 最大値プーリング(max pooling) : フィルタでのmax値を出す
- 平均値プーリング(average pooling) :フィルタでのmean値を出す

### im2col

画像を行列計算するために列に分割する処理。
行列の内積を算出して一気に畳み込み演算を行う
フィルタを適用する画像領域を一行化する処理することで、
１行化した画像領域と１列化したフィルタで行列積算が可能となり、計算が高速化する

## 正規化（画像）

ネットワークが深くなると、非線形変換の繰り返しによりデータ分布が変わることがある（**内部の共変量シフト**）
### Batch Normalization

全てのバッチごとに正規化(平均0、分散1化)する処理
各ノードの値をミニバッチ単位で正規化して、スケールをそろえる（バッチ正規化）
**正則化としても機能する** (L2正則化やDrropoutの必要性が小さくなる)

### Layer Normalization

レイヤーごとに正規化を行う処理
オンライン学習やRNNで使用する

### Instance Normalization

各チャネルで独立で画像の縦横方向のみで平均・分散をとる
画像分野ではバッチ正規化の代わりで注目されている

### Group Normalization

チャネルをG個でグルーピングしてLayer Normalizatoin/Instance Normalizationの中間的な正規化を行う
セグメンテーションなどで利用

# RNN

時系列データを取り扱うDL系列。RNNとかLSTMとかGRUとか

## Recurrent Neaural Network (RNN)

Reccurent : 回帰
回帰的に前の入力情報を次のネットワークに伝搬させることで、時系列データの学習を可能にしたDNN

## BPTT (Backpropagation Through Time)

時間方向の逆伝搬を行う処理
前時間の入力を別の追加したネットワークに入れこむ形にし、伝搬可能にすることで実現している

## RNNの逆伝搬

連鎖律を用いて計算していく形式でしていく。計算が難しいので検索して理解しておく

## 勾配消失

よくある層が深くなると学習ができなくなってしまうやつ。
原因は「活性化関数」を通ることで出力されるデータが段々少なくなるため
RNNでも最後の出力で活性化関数を通る関係で勾配消失が発生する

## 勾配爆発

前の情報が強すぎて逆に勾配が爆発してしまう現象
原因対策として、一定以上の勾配は閾値を取って頭打ちにする**勾配クリッピング**を用いる

## 勾配クリッピング

L2ノルムを用いて、勾配が一定以上にならないように頭打ちを行う処理

## RNNの伝搬

### 順伝搬

普通に計算。ただの計算グラフなのでそこまで考えない
**入力する地点で重みとバイアスが入り込むことを忘れないようにする**

### 逆伝搬

**登場するパラメータと出力値で連鎖律を行う**
順伝搬で使っていた+/*の計算やtanhといった活性化関数に惑わされないようにする

# AE

## Auto Encoder

生成モデルの一種。EncoderとDeconderに分かれ、適当な入力に応じて何かしらを出力するモデル
Encoder -> 潜在変数z -> Decoderの形でzに次元圧縮して何かしらの特徴に圧縮して、Decoderでその圧縮された特徴を用いてデータを出力する

入ったものを圧縮してそのまま出すしかしてないので、**中間的な画像が出せないデメリットがある**

## Variational Autoencoder

通称VAE
EncoderとDecoderの間にあるzを確率分布として平均、分散を求め、そこからサンプリングでzを取る形式になったもの

確率変数をいじれば中間的な画像を連続的に出せる

### Reparametrization Trick

VAEの学習で逆伝搬をするために、**ガウシアンノイズを用いてサンプリングを近似的に行うことで、逆伝搬可能にした方法**
直訳すると「再パラメータ化トリック」というだけあって、サンプリングの処理をガウシアンノイズのパラメータで行うトリックを用いている

### posterior collpage

**VAEの問題** 表現力が高いDecoder(例:PixelCNN)などを用いると潜在変数が無視された生成が出てしまう
対策として潜在変数zを離散的なベクトルに変えたVQ-VAEなどがある

## VQ-VAE

潜在変数に離散ベクトルを用いて学習させることで、上記の問題を解決させたVAE

## GAN

いつもの。Generative Adversal Network(敵生成ネットワーク)
GeneratorとDiscriminatorを戦闘させて学習していくニセ札と警察の関係的な発想で生まれたネットワーク

# 強化学習

## 教師あり学習

正解がわかっているデータをもとに、入力データと対応する正解の出力の関係を学習する
画像分類などが該当

## 教師なし学習

与えられたデータが持つ構造そのものを学習。正解そのものが無い
SVMやクラスタリングが該当
## 強化学習

**報酬**をもとに、最適な意思決定を作成するための学習方法
五目並べとか遺伝子的アルゴリズムとかが該当

## マルコフ決定過程

「状態」 + 「行動」+ 「報酬」で最適化を行う処理
確率的に変化させる決定に報酬や行動によるウェイトを追加したもの

### マルコフ過程

「状態」で一意に決まる確率過程のこと
数学者であるアンドレイ・マルコフにちなんで命名された
これに「行動」と「報酬」が入るとマルコフ決定過程になる
### マルコフ性

今の状態に応じて次の状態が決定するという性質。
*今*が次を決めるやつ。過去の自分に影響されたり、未来からドラ〇もんが来て状態が勝手に変化するとかは無いよっていうやつ

## 方策

どう行動を決定するかを考えるための決まりや戦略の基準となる部分。

### 割引率

**未来に対する報酬に対する影響に対して重みづけを行うための報酬のウェイト値**
直近だけでなく、未来の報酬もある程度考慮して考えるための影響度の度合い

### 累積報酬和

価値を表す総和の式。
R = 直近の報酬 + 次の報酬 * 割引率 + さらに次の報酬 * 割引率^2 + ... = 報酬*時間分の割引率の総和

上を価値関数として見て、最大化するのが目的となる


### 価値関数

強化学習における目的関数のこと
実質的に累積報酬和をmaxへ持っていくための行動と状態を表す式が価値関数になる

### 最適ベルマン方程式

*「今の価値」* + **今後の価値の期待値**で決まる価値関数
「価値を最大化する行動」 = 「価値を最大かする最適な方策」を結びつけることが出来る

## 強化学習におけるアプローチ

### 価値関数ベース

価値を最大化するような行動をする（最適な行動をする）のを軸に評価するアプローチ
**価値そのものをモデル化**して、行動自体は別のアルゴリズムに代用させる形式

### 方策ベース

価値を最大するような行動ルール(方策)を見つけようとするのを軸に評価するアプローチ
**方策（行動の選択方法）をモデル化**する方式




